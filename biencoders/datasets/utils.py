import os
import torch
import random
import torchaudio
import logging
import torch.nn.functional as F

logging.basicConfig(
    level=logging.DEBUG if os.environ.get('DEBUG') == '1' else logging.INFO,
    format='[%(levelname)s] %(filename)s | %(message)s'
)



def add_white_noise(waveform, noise_factor=0.005):
    """
    Adds white noise to the input waveform.

    White noise is a random signal with a constant power spectral density. This function generates
    white noise matching the shape of the waveform and scales it by the provided factor before adding
    it to the original waveform.

    Parameters:
        waveform (Tensor): The input audio waveform as a PyTorch tensor. This tensor can be of shape
                           (channels, samples) where each channel is processed.
        noise_factor (float): A scaling factor for the noise amplitude. Default is 0.005. Higher values
                              increase the noise level, while lower values result in subtler noise addition.

    Returns:
        Tensor: The waveform with white noise added.
    """
    noise = torch.randn_like(waveform) * noise_factor
    return waveform + noise


def add_brownian_noise(waveform, noise_factor=0.005):
    """
    Adds brownian (red) noise to an input waveform.

    Brownian noise is generated by computing the cumulative sum of white noise,
    which results in a noise signal with more low-frequency components. This function
    creates brownian noise that is normalized and scaled by a given factor before
    being added to the original waveform.

    Parameters:
        waveform (Tensor): The input audio waveform as a PyTorch tensor. The expected
                            shape is (channels, samples).
        noise_factor (float): A multiplier controlling the amplitude of the brownian noise.
                                Increasing this value will increase the noise level. The default
                                value is 0.005.

    Returns:
        Tensor: The waveform with brownian noise added.
    """
    white = torch.randn_like(waveform)
    brown = torch.cumsum(white, dim=-1)
    # Normalize to keep amplitude in a similar range to the original waveform.
    brown = brown / (brown.abs().max() + 1e-7)
    return waveform + brown * noise_factor


def change_volume(waveform, gain_range=(0.8, 1.2)):
    """
    Adjusts the volume of the waveform by applying a random gain sampled from a specified range.

    This function multiplies the input waveform by a gain value, uniformly sampled from the provided
    gain_range tuple. This allows for controlled attenuation or amplification of the audio signal.

    Parameters:
        waveform (Tensor): The input audio waveform as a PyTorch tensor. It is typically expected
                            to have the shape (channels, samples).
        gain_range (tuple of float): A tuple of two floats (min_gain, max_gain) defining the range
                                        from which the random gain is uniformly sampled. The default
                                        range (0.8, 1.2) results in slight attenuation or amplification.

    Returns:
        Tensor: The waveform after the volume has been adjusted by the sampled gain.
    """
    gain = random.uniform(*gain_range)
    return waveform * gain


def pitch_shift(waveform, sample_rate=16000, n_steps_range=(-4, 4)):
    """
    Shifts the pitch of the waveform by a number of semitones.
    Uses sox effects from torchaudio.
    
    Args:
        waveform (Tensor): Input audio waveform.
        sample_rate (int): Sampling rate of the waveform.
        n_steps_range (tuple): Range (in semitones) from which to sample the shift.
        
    Returns:
        Tensor: The pitch-shifted waveform.
    """
    n_steps = random.uniform(*n_steps_range)
    # sox effect parameter: pitch expects cents (100 cents = 1 semitone)
    effect = [["pitch", str(n_steps * 100)], ["rate", str(sample_rate)]]
    shifted_waveform, _ = torchaudio.sox_effects.apply_effects_tensor(waveform, sample_rate, effect)
    return shifted_waveform


def add_room_impulse_response(waveform, rir_length=4000, decay=1.0):
    """
    Adds a room impulse response (simulated reverberation) to the waveform by convolution.
    
    Args:
        waveform (Tensor): Audio waveform of shape (channels, samples).
        rir_length (int): Length of the impulse response.
        decay (float): Decay factor for the exponential.
    
    Returns:
        Tensor: Reverberated waveform.
    """
    channels, samples = waveform.shape
    # Create a simple exponentially decaying impulse response.
    t = torch.linspace(0, 1, rir_length)
    rir = torch.exp(-decay * t).unsqueeze(0)  # shape (1, rir_length)
    rir = rir / (rir.abs().max() + 1e-7)
    # Replicate the impulse response for each channel.
    rir = rir.repeat(channels, 1).unsqueeze(1)  # shape (channels, 1, rir_length)
    # Prepare waveform: add batch dimension --> (1, channels, samples)
    waveform_batch = waveform.unsqueeze(0)
    # Calculate symmetric padding for same length convolution.
    left_pad = (rir_length - 1) // 2
    right_pad = rir_length - 1 - left_pad
    # Pad to account for the filter length.
    padded = F.pad(waveform_batch, (left_pad, right_pad))
    # Apply convolution channel-wise.
    reverberated = F.conv1d(padded, rir, groups=channels)
    return reverberated.squeeze(0)


def frequency_masking(waveform, freq_mask_param=50):
    """
    Applies frequency masking directly on the waveform by zeroing out a block of frequencies.
    
    This is done by performing an FFT, masking a contiguous set of frequency bins,
    and then converting back to time domain with an inverse FFT.
    
    Args:
        waveform (Tensor): Audio waveform of shape (channels, samples).
        freq_mask_param (int): Maximum width (in frequency bins) to mask.
        
    Returns:
        Tensor: Waveform with frequency masking applied.
    """
    channels, samples = waveform.shape
    # Compute FFT along the time dimension. Using rfft returns only non-negative frequency bins.
    fft_waveform = torch.fft.rfft(waveform)
    num_freq_bins = fft_waveform.shape[-1]
    # Determine random mask width and start index.
    mask_width = random.randint(0, freq_mask_param)
    if mask_width == 0 or num_freq_bins - mask_width <= 0:
        return waveform
    freq_start = random.randint(0, num_freq_bins - mask_width)
    # Zero out the selected frequency bins.
    fft_waveform[..., freq_start:freq_start+mask_width] = 0
    # Inverse FFT to get back to time domain.
    masked_waveform = torch.fft.irfft(fft_waveform, n=samples)
    return masked_waveform


def random_augment(waveform, sample_rate=16000):
    """
    Randomly applies one of the available augmentations.
    
    The available transformations include white noise, brownian noise, volume change,
    pitch shift, room impulse response, frequency masking, or no augmentation.
    """
    transforms = [
        add_white_noise,
        add_brownian_noise,
        change_volume,
        # pitch_shift,
        add_room_impulse_response,
        frequency_masking,
        lambda x: x  # identity (no augmentation)
    ]
    transform = random.choice(transforms)
    # Get transform function name safely
    transform_name = getattr(transform, "__name__", "identity")
    logging.debug("Using augmentation: %s", transform_name)
    
    # Some transforms require the sample_rate parameter.
    if transform == pitch_shift:
        return transform(waveform, sample_rate=sample_rate)
    return transform(waveform)


if __name__ == '__main__':
    # Test transforms on a synthetic sine wave
    sample_rate = 16000
    duration = 2  # seconds
    t = torch.linspace(0, duration, int(sample_rate * duration))
    waveform = torch.sin(2 * 3.14159 * 440 * t).unsqueeze(0)
    
    print("Original waveform shape:", waveform.shape)
    
    waveform_white = add_white_noise(waveform)
    print("White-noise waveform shape:", waveform_white.shape)
    
    waveform_brown = add_brownian_noise(waveform)
    print("Brownian-noise waveform shape:", waveform_brown.shape)
    
    waveform_volume_changed = change_volume(waveform)
    print("Volume changed waveform shape:", waveform_volume_changed.shape)
    
    # waveform_pitch_shifted = pitch_shift(waveform, sample_rate=sample_rate)
    # print("Pitch shifted waveform shape:", waveform_pitch_shifted.shape)
    
    waveform_reverb = add_room_impulse_response(waveform)
    print("Reverberated waveform shape:", waveform_reverb.shape)
    
    waveform_freq_masked = frequency_masking(waveform)
    print("Frequency masked waveform shape:", waveform_freq_masked.shape)
    
    waveform_augmented = random_augment(waveform, sample_rate=sample_rate)
    print("Randomly augmented waveform shape:", waveform_augmented.shape)
